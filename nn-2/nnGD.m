function [L_history, thetaho, thetaih] = nnGD(X, Y, thetaih, thetaho, lambda, niter, alpha)    nTrain = length(Y)    L_history = zeros(niter, 1)        for i = 1:niter                [L, gradho, gradih] = nnCostFunctionSig(X, Y, thetaih, thetaho, lambda)        L_history(i) = L% get loss function for training and validation data set for each iteration                thetaho = thetaho - alpha * gradho        thetaih = thetaih - alpha * gradih % update weights based on gradient    end        end